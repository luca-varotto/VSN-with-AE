import numpy as np
import pandas as pd
import os
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.model_selection import train_test_split
from sklearn.metrics import classification_report
import keras
from keras.models import Sequential
from keras.layers import Dense, Dropout, Conv2D, MaxPool2D, UpSampling2D, Activation
from keras import backend as K
from sklearn.cluster import KMeans
from sklearn.metrics import confusion_matrix
from keras.datasets import mnist

train = pd.read_csv("./input/train.csv")
test = pd.read_csv("./input/test.csv")

# Get X and y for training
X = train.drop(['label'], axis=1)
y = train['label']

print(np.shape(X), type(X), type(y))

# # Train, Test and Validate Split
# X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, stratify=y, random_state=123)
# X_train, X_validate, y_train, y_validate = train_test_split(X_train, y_train, test_size=0.25, stratify=y_train, random_state=123)

# # Reshape and Rescale the images
# X_train = X_train.values.reshape(-1,28,28,1) / 255
# X_test = X_test.values.reshape(-1,28,28,1) / 255
# X_validate = X_validate.values.reshape(-1,28,28,1) / 255


# # Build the autoencoder
# model = Sequential()
# model.add(Conv2D(14, kernel_size=3, padding='same', activation='relu', input_shape=(28,28,1)))
# model.add(MaxPool2D((2,2), padding='same'))
# model.add(Dropout(0.2))
# model.add(Conv2D(7, kernel_size=3, padding='same', activation='relu'))
# model.add(MaxPool2D((2,2), padding='same'))
# model.add(Dropout(0.2))
# model.add(Conv2D(7, kernel_size=3, padding='same', activation='relu'))
# model.add(UpSampling2D((2,2)))
# model.add(Dropout(0.2))
# model.add(Conv2D(14, kernel_size=3, padding='same', activation='relu'))
# model.add(UpSampling2D((2,2)))
# model.add(Dropout(0.2))
# model.add(Conv2D(1, kernel_size=3, padding='same', activation='relu'))

# model.compile(optimizer='adam', loss="mse")
# model.summary()

# # Train the model
# model.fit(X_train, X_train, epochs=3, batch_size=64, validation_data=(X_validate, X_validate), verbose=1)

# # Fitting testing dataset
# restored_testing_dataset = model.predict(X_test)

# # Observe the reconstructed image quality
# plt.figure(figsize=(20,5))
# for i in range(10):
#     index = y_test.tolist().index(i)
#     plt.subplot(2, 10, i+1)
#     plt.imshow(X_test[index].reshape((28,28)))
#     plt.gray()
#     plt.subplot(2, 10, i+11)
#     plt.imshow(restored_testing_dataset[index].reshape((28,28)))
#     plt.gray()

# # Extract the encoder
# encoder = K.function([model.layers[0].input], [model.layers[4].output])

# # Encode the training set
# encoded_images = encoder([X_test])[0].reshape(-1,7*7*7)

# # Cluster the training set
# kmeans = KMeans(n_clusters=10)
# clustered_training_set = kmeans.fit_predict(encoded_images)

# # Observe and compare clustering result with actual label using confusion matrix
# cm = confusion_matrix(y_test, clustered_training_set)
# plt.figure(figsize=(10, 10))
# sns.heatmap(cm, annot=True, fmt="d")
# plt.title("Confusion matrix", fontsize=30)
# plt.ylabel('True label', fontsize=25)
# plt.xlabel('Clustering label', fontsize=25)
# plt.show()

# # Plot the actual pictures grouped by clustering
# fig = plt.figure(figsize=(20,20))
# for r in range(10):
#     cluster = cm[r].argmax()
#     for c, val in enumerate(X_test[clustered_training_set == cluster][0:10]):
#         fig.add_subplot(10, 10, 10*r+c+1)
#         plt.imshow(val.reshape((28,28)))
#         plt.gray()
#         plt.xticks([])
#         plt.yticks([])
#         plt.xlabel('cluster: '+str(cluster))
#         plt.ylabel('digit: '+str(r))